# Extraction-Of-articles-
In this project I have extracted the articles using web scraping with the help of NLTK libraries. First I have imported all the necessary NLTK libraries and with beautiful soup library, I have extracted only the content parsing with html parser.
And then tokenization takes place and setting words in lower case to remove the stopwords and removing the number as well.
The main motto is too calculate the positive, negative and compound scores of the data and to calculate some functions to see the data readability.
These are the some functions I have calculated:
Getting positive and negative score.
Number of words present in given file(Wordcount)
polarity,subjectivity scores
average sentence length
Number of Complex words in the file
percentage of complex words
fog index
average word length
syllable count
This project is based on implementation of various NLTK libraries to see ho the real time data is!! And I hope this finds you well.Thank you all
